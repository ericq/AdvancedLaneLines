{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "## preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, I'll compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calibrate camera using collection of chessboard pictures. \n",
    "# Note: \n",
    "# 1. calibration will not happen if found coners less than half of the checkboard images \n",
    "# 2. Same image size for the correlation image and future image to be undistorted\n",
    "# images_path: input file name patterns, default value:camera_cal/calibration*.jpg\n",
    "# corner_num_x: number of corners along the x axis, default value:9\n",
    "# corner_num_y: number of corners along the y axis, default value:6\n",
    "# output_path:  output the corner found images for debugging purpose. default value:\"camera_cal_output\"\n",
    "# img_size: this corresponds to the picture to be undistorted. default value: None, use the calibration img size\n",
    "#\n",
    "# The size of the image, which is passed into the calibrateCamera function, is just the height and width of the image.\n",
    "# One way to retrieve these values is by retrieving them from the grayscale image shape array gray.shape[::-1]. \n",
    "# This returns the image width and height in pixel values like (1280, 960).\n",
    "# Another way to retrieve the image shape, is to get them directly from the color image by retrieving the first two \n",
    "# values in the color image shape array using img.shape[1::-1]. This code snippet asks for just the first two values \n",
    "# in the shape array, and reverses them. Note that in our case we are working with a greyscale image, \n",
    "# so we only have 2 dimensions (color images have three, height, width, and depth), so this is not necessary.\n",
    "\n",
    "# Return value - same as cv2.calibrateCamera return\n",
    "# plus result saved to <output_path>/cam_calibration_result_pickle.p for future use\n",
    " \n",
    "\n",
    "def calibrate_camera (images_path=\"camera_cal/calibration*.jpg\", corner_num_x=9, corner_num_y=6, output_path=\"camera_cal_output/\", img_size=None):\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((corner_num_y*corner_num_x,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:corner_num_x, 0:corner_num_y].T.reshape(-1,2)\n",
    "\n",
    "    # Make a list of calibration images\n",
    "    images = glob.glob(images_path)\n",
    "\n",
    "\n",
    "    objpoints = [] # 3D points in real world space\n",
    "    imgpoints = [] # 2D points in img plane\n",
    "\n",
    "    # prepare output file dir\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "    # Step through the list and search for chessboard corners\n",
    "    corners_found = 0\n",
    "    for idx, fname in enumerate(images):\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (corner_num_x,corner_num_y), None)\n",
    "\n",
    "        # If found, add object points, image points\n",
    "        if ret == True:\n",
    "            corners_found += 1\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "\n",
    "            # Draw and display the corners\n",
    "            cv2.drawChessboardCorners(img, (corner_num_x,corner_num_y), corners, ret)\n",
    "            write_name = output_path+'corners_found_in_'+os.path.basename(fname)\n",
    "            cv2.imwrite(write_name, img)\n",
    "            print (\"corners found and saved as:\" + write_name)\n",
    "\n",
    "        else:\n",
    "            print (\"coners not found in: \" + fname)\n",
    "       \n",
    "    \n",
    "    if corners_found > idx / 2:\n",
    "        print (\"OK: found cornders in more than half of the input images, carry on with calibration\")\n",
    "        if img_size is None:\n",
    "            img_size = (img.shape[1], img.shape[0])\n",
    "            print(\"img_size is None, use calibration img size: \" + str(img_size))\n",
    "            \n",
    "            \n",
    "        ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size,None,None)\n",
    "        \n",
    "        # Save the camera calibration result for later use (we won't worry about rvecs / tvecs)\n",
    "        dist_pickle = {}\n",
    "        dist_pickle[\"mtx\"] = mtx\n",
    "        dist_pickle[\"dist\"] = dist\n",
    "        cam_calibration_result = output_path+\"cam_calibration_result_pickle.p\"\n",
    "        pickle.dump( dist_pickle, open( cam_calibration_result, \"wb\" ) )\n",
    "        \n",
    "        print(\"camera calibration result saved in file \" + cam_calibration_result + \" for future use\" )\n",
    "    \n",
    "        return ret, mtx, dist, rvecs, tvecs\n",
    "        \n",
    "    else:\n",
    "        print (\"Error: found cornders in less than half of the input images, stopped calibration.\")\n",
    "        return -1, None, None, None, None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Note of Applying a distortion correction to raw images.\n",
    "No wrapping code needed. please use cv2.undistort directly in the future pipeline.\n",
    "Example code below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the saved camera matrix and distortion coefficients from the pickle dump file\n",
    "# dist_pickle = pickle.load( open( \"wide_dist_pickle.p\", \"rb\" ) )\n",
    "# mtx = dist_pickle[\"mtx\"]\n",
    "# dist = dist_pickle[\"dist\"]\n",
    "# Use the OpenCV undistort() function to remove distortion\n",
    "# undist = cv2.undistort(img, mtx, dist, None, mtx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then, Use color transforms, gradients, etc., to create a thresholded binary image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a function that takes an image, number of x and y points, \n",
    "# camera matrix and distortion coefficients\n",
    "def corners_unwarp(img, nx, ny, mtx, dist):\n",
    "    # Use the OpenCV undistort() function to remove distortion\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    # Convert undistorted image to grayscale\n",
    "    gray = cv2.cvtColor(undist, cv2.COLOR_BGR2GRAY)\n",
    "    # Search for corners in the grayscaled image\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "\n",
    "    if ret == True:\n",
    "        # If we found corners, draw them! (just for fun)\n",
    "        cv2.drawChessboardCorners(undist, (nx, ny), corners, ret)\n",
    "        # Choose offset from image corners to plot detected corners\n",
    "        # This should be chosen to present the result at the proper aspect ratio\n",
    "        # My choice of 100 pixels is not exact, but close enough for our purpose here\n",
    "        offset = 100 # offset for dst points\n",
    "        # Grab the image shape\n",
    "        img_size = (gray.shape[1], gray.shape[0])\n",
    "\n",
    "        # For source points I'm grabbing the outer four detected corners\n",
    "        src = np.float32([corners[0], corners[nx-1], corners[-1], corners[-nx]])\n",
    "        # For destination points, I'm arbitrarily choosing some points to be\n",
    "        # a nice fit for displaying our warped result \n",
    "        # again, not exact, but close enough for our purposes\n",
    "        dst = np.float32([[offset, offset], [img_size[0]-offset, offset], \n",
    "                                     [img_size[0]-offset, img_size[1]-offset], \n",
    "                                     [offset, img_size[1]-offset]])\n",
    "        # Given src and dst points, calculate the perspective transform matrix\n",
    "        M = cv2.getPerspectiveTransform(src, dst)\n",
    "        # Warp the image using OpenCV warpPerspective()\n",
    "        warped = cv2.warpPerspective(undist, M, img_size)\n",
    "\n",
    "    # Return the resulting image and matrix\n",
    "    return warped, M\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline linking all processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect lane from a image file\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def adv_lane_detection_pipeline(initial_img_path, calibration_mtx, calibration_dist):\n",
    "    img = cv2.imread(initial_img_path)\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    \n",
    "    # Apply a distortion correction to raw images.\n",
    "    undist = cv2.undistort(img, calibration_mtx, calibration_dist, None, calibration_mtx)\n",
    "\n",
    "    # Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "    \n",
    "    ## Convert undistorted image to grayscale\n",
    "    #gray = cv2.cvtColor(undist, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "\n",
    "    \n",
    "    # Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "    \n",
    "    \n",
    "    # Detect lane pixels and fit to find the lane boundary.\n",
    "    \n",
    "    \n",
    "    # Determine the curvature of the lane and vehicle position with respect to center.\n",
    "    \n",
    "    \n",
    "    # Warp the detected lane boundaries back onto the original image.\n",
    "    \n",
    "    \n",
    "    # Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "    result = undist\n",
    "\n",
    "    return result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coners not found in: camera_cal/calibration5.jpg\n",
      "coners not found in: camera_cal/calibration4.jpg\n",
      "corners found and saved as:camera_cal_output/corners_found_in_calibration6.jpg\n",
      "corners found and saved as:camera_cal_output/corners_found_in_calibration7.jpg\n",
      "corners found and saved as:camera_cal_output/corners_found_in_calibration3.jpg\n",
      "corners found and saved as:camera_cal_output/corners_found_in_calibration2.jpg\n",
      "coners not found in: camera_cal/calibration1.jpg\n",
      "corners found and saved as:camera_cal_output/corners_found_in_calibration20.jpg\n",
      "corners found and saved as:camera_cal_output/corners_found_in_calibration19.jpg\n",
      "corners found and saved as:camera_cal_output/corners_found_in_calibration18.jpg\n",
      "corners found and saved as:camera_cal_output/corners_found_in_calibration15.jpg\n",
      "corners found and saved as:camera_cal_output/corners_found_in_calibration14.jpg\n",
      "corners found and saved as:camera_cal_output/corners_found_in_calibration16.jpg\n",
      "corners found and saved as:camera_cal_output/corners_found_in_calibration17.jpg\n",
      "corners found and saved as:camera_cal_output/corners_found_in_calibration13.jpg\n",
      "corners found and saved as:camera_cal_output/corners_found_in_calibration12.jpg\n",
      "corners found and saved as:camera_cal_output/corners_found_in_calibration10.jpg\n",
      "corners found and saved as:camera_cal_output/corners_found_in_calibration11.jpg\n",
      "corners found and saved as:camera_cal_output/corners_found_in_calibration9.jpg\n",
      "corners found and saved as:camera_cal_output/corners_found_in_calibration8.jpg\n",
      "OK: found cornders in more than half of the input images, carry on with calibration\n",
      "img_size is None, use calibration img size: (1280, 720)\n",
      "camera calibration result saved in file camera_cal_output/cam_calibration_result_pickle.p for future use\n",
      "1.0298149716172795\n"
     ]
    }
   ],
   "source": [
    "# Calibrate camera\n",
    "\n",
    "ret, mtx, dist, rvecs, tvecs = calibrate_camera()\n",
    "print(ret)\n",
    "\n",
    "if ret < 0:\n",
    "    print (\"Error: calibration camera failed.\")\n",
    "    exit \n",
    "\n",
    "# iterate through every input file\n",
    "INPUT_DIR = \"test_images/\"\n",
    "OUTPUT_DIR = \"test_images_output/\"\n",
    "os.makedirs(os.path.dirname(OUTPUT_DIR), exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(INPUT_DIR):    \n",
    "    result_img = adv_lane_detection_pipeline (INPUT_DIR+filename, mtx, dist)\n",
    "    cv2.imwrite(OUTPUT_DIR+filename, result_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#top_down, perspective_M = corners_unwarp(img, nx, ny, mtx, dist)\n",
    "#f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "#f.tight_layout()\n",
    "#ax1.imshow(img)\n",
    "#ax1.set_title('Original Image', fontsize=50)\n",
    "#ax2.imshow(top_down)\n",
    "#ax2.set_title('Undistorted and Warped Image', fontsize=50)\n",
    "#plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
